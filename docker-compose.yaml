version: "3"
services:
  Roboflow-GPU-1:
    image: roboflow/roboflow-inference-server-trt
    restart: always
    environment:
      - CUDA_VISIBLE_DEVICES=0 #A2 - They have device IDs
      - MODEL_CACHE_DIR=/tmp/cache
    volumes:
      - shared-volume:/tmp/cache
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu]
  Roboflow-GPU-2:
    image: roboflow/roboflow-inference-server-trt
    restart: always
    environment:
      - CUDA_VISIBLE_DEVICES=0 #A2 - They have device IDs
      - MODEL_CACHE_DIR=/tmp/cache
    volumes:
      - shared-volume:/tmp/cache
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu]
  Load-Balancer:
    image: lb
    restart: always
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_CACHE_DIR=/tmp/cache
    ports:
      - 9001:80

volumes:
  shared-volume:
